---
title: "TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions"
authors: "Linli Yao, Yuancheng Wei, Yaojie Zhang, Lei Li, Xinlong Chen, Feifan Song, Ziyue Wang, Kun Ouyang, Yuanxin Liu, Lingpeng Kong"
url: "https://huggingface.co/papers/2602.08711"
upvotes: 17
tags: ["Video Understanding", "Dense Captioning", "GRPO", "Multimodal"]
focus_area: false
---

# TimeChat-Captioner: 用时间感知的结构化音视觉字幕描述多场景视频

## 一句话总结
提出"全方位密集字幕"任务和 TimeChat-Captioner-7B 模型，通过六维结构化描述生成电影剧本式的视频叙事，超越 Gemini-2.5-Pro。

## 关键创新
- **全方位密集字幕（Omni Dense Captioning）**任务：生成带时间戳的连续、细粒度、结构化音视觉叙事
- **六维结构化模式**：创建"剧本式"字幕，让读者能逐场景想象视频内容
- **SodaM 统一评估指标**：评估时间感知的详细描述，同时缓解场景边界模糊性
- **SFT + GRPO 训练**：结合监督微调和带任务特定奖励的 GRPO

## 方法概述
首先定义全方位密集字幕任务，要求模型生成带时间戳的结构化音视觉叙事。设计六维结构化模式，使字幕像电影剧本一样可读。构建了 OmniDCBench 人工标注基准和 TimeChatCap-42K 训练数据集。TimeChat-Captioner-7B 通过 SFT 和带任务特定奖励的 GRPO 训练，实现最先进性能。

## 主要结果
- 超越 **Gemini-2.5-Pro** 的密集字幕质量
- 生成的密集描述显著提升下游音视觉推理（DailyOmni 和 WorldSense）
- 在时序定位（Charades-STA）上也表现出色

## 复现指南
- 代码和数据集将在 GitHub 发布：https://github.com/yaolinli/TimeChat-Captioner
- 基于 7B 规模模型，单卡可训练
- 需要 TimeChatCap-42K 训练数据

## 要点总结
1. 视频理解从简单描述走向结构化剧本式叙事
2. GRPO 在视频字幕任务中被成功应用
3. 好的密集字幕可以显著提升下游任务性能