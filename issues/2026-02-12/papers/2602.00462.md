---
title: "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs"
authors: "Benno Krojer, Shravan Nayak, Oscar Mañas, Vaibhav Adlakha, Desmond Elliott, Siva Reddy, Marius Mosbach"
url: "https://huggingface.co/papers/2602.00462"
upvotes: 14
tags: ["Interpretability", "VLM", "Visual Tokens", "Representation Analysis"]
focus_area: false
---

# LatentLens: 揭示 LLM 中高度可解释的视觉 Token

## 一句话总结
LatentLens 通过将视觉 token 的潜在表示与上下文化文本表示进行最近邻匹配，揭示了 VLM 中大多数视觉 token 在所有层都是可解释的。

## 关键创新
- **LatentLens 方法**：将潜在表示映射到自然语言描述的新方法
- **上下文化文本表示匹配**：预先编码大量文本语料，存储上下文化 token 表示，用 KNN 匹配视觉 token
- **推翻 LogitLens 结论**：证明 LogitLens 显著低估了视觉 token 的可解释性

## 方法概述
LatentLens 首先对大量文本语料进行编码，为每个 token 存储上下文化表示。然后将视觉 token 表示与这些文本表示进行比较，top-k 最近邻表示提供对视觉 token 的自然语言描述。该方法在 10 个不同 VLM 上进行了评估。

## 主要结果
- 在 10 个 VLM 上，大多数视觉 token 在所有层都是可解释的
- 常用方法 LogitLens 显著低估了视觉 token 的可解释性
- LatentLens 生成的描述语义有意义，比单个 token 提供更细粒度的解释

## 复现指南
- 需要大量文本语料用于构建表示库
- 在标准 VLM（LLaVA 等）上运行
- 计算开销主要在预编码文本语料阶段

## 要点总结
1. 视觉 token 在 LLM 中的可解释性被严重低估
2. 上下文化表示比 logit 空间投影更能反映视觉 token 的语义
3. 视觉-语言表示对齐比预想中更紧密
4. 为分析 VLM 的内部表示开辟了新方向