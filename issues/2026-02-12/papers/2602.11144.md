---
title: "GENIUS: Generative Fluid Intelligence Evaluation Suite"
authors: "Ruichuan An, Sihan Yang, Ziyu Guo, Wei Dai, Zijun Shen, Haodong Li, Renrui Zhang, Xinyu Wei, Guopeng Li, Wenshan Wu, Wentao Zhang"
url: "https://huggingface.co/papers/2602.11144"
upvotes: 36
tags: ["Benchmark", "Multimodal", "Visual Generation", "Evaluation"]
focus_area: false
---

# GENIUS: 生成式流体智力评估套件

## 一句话总结
GENIUS 提出了一个评估统一多模态模型（UMM）"生成式流体智力"的基准，揭示现有模型在模式归纳、约束执行和上下文适应方面的显著不足。

## 关键创新
- **生成式流体智力（GFI）**概念：区别于依赖已有知识的"结晶智力"，关注模型在新场景中即时推理和适应的能力
- **三原语形式化**：归纳隐式模式、执行临时约束、适应上下文知识
- **无训练注意力干预策略**：无需训练即可提升模型的上下文理解能力

## 方法概述
将生成式流体智力分解为三个基本能力原语：（1）归纳隐式模式——如推断个性化视觉偏好；（2）执行临时约束——如将抽象隐喻可视化；（3）适应上下文知识——如模拟反直觉物理。基准测试中，系统评估了 12 个代表性模型，并通过诊断分析区分了失败模式的来源。

## 主要结果
- 12 个代表性模型在 GFI 任务上表现显著不足
- 诊断分析表明缺陷源于有限的上下文理解能力，而非生成能力不足
- 提出的无训练注意力干预策略可有效缩小差距

## 复现指南
- 数据集和代码将在 GitHub 发布：https://github.com/arctanxarc/GENIUS
- 评估需要支持视觉生成的统一多模态模型
- 可在标准 GPU 上运行评估流水线

## 要点总结
1. 现有 VLM 评估过度关注"记忆"能力，忽视了即时推理
2. 模型的生成能力并不差，瓶颈在于上下文理解
3. 为多模态模型评估开辟了新维度